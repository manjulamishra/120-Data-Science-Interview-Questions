{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjulamishra/120-Data-Science-Interview-Questions/blob/master/document_classification_using_layoutLMv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "https://youtu.be/HFHI8C44Q2w\n"
      ],
      "metadata": {
        "id": "Pn_MVFxn8591"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcSY74ok5xhc",
        "outputId": "edf48373-c54f-4ed5-988a-5e3a733a4b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.7.2 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq Selenium --progress-bar off\n",
        "!pip install -qqq Selenium-Screenshot --progress-bar off\n",
        "!pip install -qqq transformers==4.20.1 --progress-bar off\n",
        "!pip install -qqq pytorch-lightning==1.6.4 --progress-bar off\n",
        "!pip install -qqq pytesseract --progress-bar off\n",
        "!pip install -qqq Pillow==9.0.1 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq update > /dev/null\n",
        "!apt -qq install chromium-chromedriver > /dev/null  \n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!apt -qq install tesseract-ocr > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkB9B90A4jUQ",
        "outputId": "7811facd-1d1b-480b-9da0-5c0a1f315d61"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1x02cIc-F_ExpoUvxIeRNPo3DZrGwg-Q9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3vLNKvg7L8m",
        "outputId": "0a55b086-050a-4360-cbd9-04b5290d8cfa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x02cIc-F_ExpoUvxIeRNPo3DZrGwg-Q9\n",
            "To: /content/kaggle_financial_document_clustering_dataset.zip\n",
            "\r  0% 0.00/3.10M [00:00<?, ?B/s]\r100% 3.10M/3.10M [00:00<00:00, 215MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q kaggle_financial_document_clustering_dataset.zip"
      ],
      "metadata": {
        "id": "o_mNG2O07r83"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"TableClassifierQuaterlyWithNotes/\" \"documents\""
      ],
      "metadata": {
        "id": "apR00lfd8Bqz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7_3jPYa8Y_w",
        "outputId": "2b1c3c4f-2368-4697-a77b-3459d65c2a57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents  kaggle_financial_document_clustering_dataset.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib"
      ],
      "metadata": {
        "id": "1s0tqAeFJqYH"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LayoutLMv3FeatureExtractor, LayoutLMv3TokenizerFast, LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
        "from selenium import webdriver\n",
        "# from Screenshot import Screenshot_clipping\n",
        "# from Screenshot.Screenshot_Clipping import Screenshot\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "id": "5YxXg4Y18mcu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the dir to lowecase name\n",
        "for dir in Path(\"documents\").glob(\"*\"):\n",
        "  dir.rename(str(dir).lower().replace(\" \", \"_\"))"
      ],
      "metadata": {
        "id": "UNq3Eip1V62f"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(Path(\"documents\").glob(\"*\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibOcNi8bXJbM",
        "outputId": "1c2d1e70-8331-4de7-eead-91cac592e0be"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('documents/income_statement'),\n",
              " PosixPath('documents/notes'),\n",
              " PosixPath('documents/cash_flow'),\n",
              " PosixPath('documents/balance_sheets'),\n",
              " PosixPath('documents/others')]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let'save the images into a new dir\n",
        "\n",
        "for dir in Path(\"documents\").glob(\"*\"):\n",
        "  image_dir = Path(f\"images/{dir.name}\")\n",
        "  image_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "metadata": {
        "id": "2Tpxt-ULY9YB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if it created the right dir and path"
      ],
      "metadata": {
        "id": "JdY7IXE2Y9a5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(Path(\"images\").glob(\"*\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH1icT7dY9dO",
        "outputId": "5b5073f4-f250-4edd-e457-950b7c414bcf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('images/income_statement'),\n",
              " PosixPath('images/notes'),\n",
              " PosixPath('images/cash_flow'),\n",
              " PosixPath('images/balance_sheets'),\n",
              " PosixPath('images/others')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=chrome_options)"
      ],
      "metadata": {
        "id": "bfrWKfy0MhCZ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils.text import Path\n",
        "# write a function to convert html to images\n",
        "\n",
        "def convert_html_to_image(driver:webdriver.Chrome, file_path: Path, images_dir: Path) -> Path:\n",
        "  driver.get(f\"file:///content/{str(file_path)}\")\n",
        "\n",
        "  save_path = f\"{str(images_dir)}/{file_path.parent.name}\"\n",
        "  image_name=file_path.with_suffix(\".png\").name\n",
        "  driver.get_screenshot_as_file(f\"{save_path}/{image_name}\")\n",
        "\n",
        "  return Path(save_path)"
      ],
      "metadata": {
        "id": "tuCuXM4PbD2b"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyl0KJ4QiKPh",
        "outputId": "86a66b2d-9424-4df2-ddfc-2103e19b97aa"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents  kaggle_financial_document_clustering_dataset.zip  screenshot.png\n",
            "images\t   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test it on first 10 docs\n",
        "\n",
        "document_paths = list(Path(\"documents\").glob(\"*/*\"))[:10]\n",
        "\n",
        "for doc_path in tqdm(document_paths):\n",
        "  convert_html_to_image(driver, doc_path, Path(\"images\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dZYXJfUbD4_",
        "outputId": "f3d5bb55-4d45-419f-cd56-ed05624bcfb2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:00<00:01,  5.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents/income_statement/18646822_1.html\n",
            "images/income_statement/18646822_1.png\n",
            "documents/income_statement/18882293_1.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:00<00:01,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/income_statement/18882293_1.png\n",
            "documents/income_statement/18902087_1.html\n",
            "images/income_statement/18902087_1.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [00:00<00:01,  5.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents/income_statement/18950001_1.html\n",
            "images/income_statement/18950001_1.png\n",
            "documents/income_statement/18853062_2.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:00<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/income_statement/18853062_2.png\n",
            "documents/income_statement/18460640_8.html\n",
            "images/income_statement/18460640_8.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [00:01<00:00,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents/income_statement/18586111_2.html\n",
            "images/income_statement/18586111_2.png\n",
            "documents/income_statement/18932217_4.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:01<00:00,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/income_statement/18932217_4.png\n",
            "documents/income_statement/18836203_12.html\n",
            "images/income_statement/18836203_12.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents/income_statement/18320959_1.html\n",
            "images/income_statement/18320959_1.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrKsOaK_tjsB",
        "outputId": "f582cbf7-56e5-424f-dee3-feb73a2983e6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('documents/income_statement/18646822_1.html'),\n",
              " PosixPath('documents/income_statement/18882293_1.html'),\n",
              " PosixPath('documents/income_statement/18902087_1.html'),\n",
              " PosixPath('documents/income_statement/18950001_1.html'),\n",
              " PosixPath('documents/income_statement/18853062_2.html'),\n",
              " PosixPath('documents/income_statement/18460640_8.html'),\n",
              " PosixPath('documents/income_statement/18586111_2.html'),\n",
              " PosixPath('documents/income_statement/18932217_4.html'),\n",
              " PosixPath('documents/income_statement/18836203_12.html'),\n",
              " PosixPath('documents/income_statement/18320959_1.html')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the above step takes some time to convert html to images\n",
        "# so let's also check if it ocmvereted them \n",
        "\n",
        "image_paths = list(Path(\"images\").glob(\"*/*\"))\n",
        "image_paths[0]\n",
        "# image = Image.open(str(image_paths[0]))\n",
        "# image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD3jvTVDbD8F",
        "outputId": "a6e23798-81f5-4fa5-89f5-4b905d40ddbe"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('images/income_statement/18950001_1.png')"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# layoutLMv3 Feature extractor\n",
        "\n",
        "feature_extractor = LayoutLMv3FeatureExtractor(apply_ocr=True, ocr_lang=\"eng\")\n",
        "tokenizer = LayoutLMv3TokenizerFast.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "processor = LayoutLMv3Processor(feature_extractor, tokenizer)"
      ],
      "metadata": {
        "id": "dMl9K319bD-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = processor(\n",
        "    image, \n",
        "    max_length=512,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "metadata": {
        "id": "CW332lWvbEBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the dict keys from the above function will be something like. These are called tensors \n",
        "# dict_keys([\"input_ids\", 'attention_mask', 'bbox', 'pixel_values'])"
      ],
      "metadata": {
        "id": "i44nhAmFhGDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "input_ids: {list(encoding[\"input_ids\"].squeeze().shape)} # max_length\n",
        "word_boxes: {list(encoding[\"bbox\"].squeeze().shape)} # same shape as id but the number 4 is for bbox top, left, bottom, right\n",
        "image data: {list(encoding[\"pixel_values\"].squeeze().shape)} # convereted into a sqaure image 3 is for RGB\n",
        "image size: {image.size}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "6jCDbRmAhGGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result will be something like: (25:43 minutes)\n",
        "\n",
        "input_ids: [512]\n",
        "word_boxes: [512, 4]\n",
        "image data: [3, 224, 224]\n",
        "image size: [769, 966]"
      ],
      "metadata": {
        "id": "E_EWnaHYiXae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's print what's in feature_extractor\n",
        "# summary of it's configuration \n",
        "feature_extractor"
      ],
      "metadata": {
        "id": "2HbxDCqRhGIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b let's use the extractor on the image\n",
        "\n",
        "features = feature_extractor(image) # this will run tesseract for us"
      ],
      "metadata": {
        "id": "rz7WFRojkyIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.keys()"
      ],
      "metadata": {
        "id": "UN_4LdYYkyK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we should get same number of bbox as word count\n",
        "\n",
        "print(f\"\"\"\n",
        "image size: {features[\"pixel_values\"][0].shape}\n",
        "word count: {len(features[\"word\"][0])}\n",
        "word boxes: {len(features[\"boxes\"][0])}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Frd37u1gkyNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features[\"boxes\"][0] #outputs some of the bounding boxes for image[0]"
      ],
      "metadata": {
        "id": "XFTDwuwskyRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image data is going to come from pixel_values\n",
        "# let's check teh shape\n",
        "\n",
        "image_data = features[\"pixel_values\"][0]\n",
        "image_data.shape"
      ],
      "metadata": {
        "id": "Dlk9P1VOmAuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to swap the dimension meaning take the transpose of the image data so [3,224,224] becomes\n",
        "# [224,224,3]\n",
        "\n",
        "image_data = image_data.transpose(1,2,0)\n",
        "image_data.shape"
      ],
      "metadata": {
        "id": "OJ9-GMvYmAxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import step to convert floats to integers 29.58 mins\n",
        "\n",
        "image_data = p.uint8(image_data * 255)\n",
        "image_data[0][0]"
      ],
      "metadata": {
        "id": "LHr3oylOmAzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally we have to open image data in array format in RGB mode\n",
        "# this is the image that's fed into the model after feature extraction\n",
        "# this is the iamge that's fed intot he model embedding \n",
        "\n",
        "Image.fromarray(image_data, mode=\"RGB\")"
      ],
      "metadata": {
        "id": "j74wD13BmA2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's take care of teh words\n",
        "\n",
        "words = features[\"words\"][0]\n",
        "bounding_boxes = features[\"boxes\"][0]\n",
        "\n",
        "print(words[:5])\n",
        "print(bounding_boxes[:5])\n",
        "\n",
        "#this prints 5 words from the top and the corresponding boxes coordinates \n"
      ],
      "metadata": {
        "id": "wDVs340eopVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's draw the bounding boxes\n",
        "\n",
        "image = Image.open(image_paths[4].convert(\"RGB\"))\n",
        "\n",
        "width_scale = image.width / 1000\n",
        "height_scale = image..height / 1000\n",
        "\n",
        "draw = Image.Draw(image)\n",
        "\n",
        "for bbox in bounding_boxes:\n",
        "  draw.rectangle(\n",
        "      [\n",
        "       bbox[0] = width_scale,\n",
        "       bbox[1] = height_scale,\n",
        "       bbox[2] = width_scale,\n",
        "       bbox[3] = width_scale\n",
        "      ], \n",
        "                 outline=\"blue\", \n",
        "                 width=2)\n",
        "image"
      ],
      "metadata": {
        "id": "g4F2V0eTopWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word tokenizer \n",
        "\n",
        "encoding = tokenizer(\n",
        "    text = words, \n",
        "    boxes = bounding_boxes,\n",
        "    max_length=512,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "metadata": {
        "id": "QW3KuLBAopX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's see what different types of tokens we have \n",
        "# print first 20 tokens to see what it looks like\n",
        "tokens = tokenizer.convert_ids_to_tokens(\n",
        "    encoding[\"input_ids\"][0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(tokens[:20])"
      ],
      "metadata": {
        "id": "Ydnmc22Sopah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to convert messy tokens\n",
        " # convert them to strings\n",
        "\n",
        " tokenizer.convert_tokens_to_string(tokens[:20])\n",
        "\n",
        " # this will put the messy looking tokens into readable format"
      ],
      "metadata": {
        "id": "69SZJz3bopdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's call teh mdoel "
      ],
      "metadata": {
        "id": "3uF34Yc6tHi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LayoutLMv3ForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\")"
      ],
      "metadata": {
        "id": "WqEi1UdrtHlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "id": "uJaJSfFltHoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = processor(\n",
        "    image,\n",
        "    max_length=512,\n",
        "    padding=\"max_length\",\n",
        "    trancation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "outputs = model(**encoding)"
      ],
      "metadata": {
        "id": "S0m1Mqf3tHrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits"
      ],
      "metadata": {
        "id": "OocTZVsEtHuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}