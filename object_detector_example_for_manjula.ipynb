{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjulamishra/120-Data-Science-Interview-Questions/blob/master/object_detector_example_for_manjula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "How should label.json look like?\n",
        "\n",
        "```\n",
        "{\n",
        "    \"image1.jpg\": [\n",
        "        {\n",
        "            \"bbox\": [50, 50, 200, 200],\n",
        "            \"label\": 0\n",
        "        },\n",
        "        {\n",
        "            \"bbox\": [100, 100, 150, 150],\n",
        "            \"label\": 1\n",
        "        }\n",
        "    ],\n",
        "    \"image2.jpg\": [\n",
        "        {\n",
        "            \"bbox\": [30, 30, 120, 120],\n",
        "            \"label\": 0\n",
        "        }\n",
        "    ],\n",
        "    // ...\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iS9v3R6b9Kz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxkeA8x730xj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "def load_and_preprocess_data(data_dir, label_file, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Load images and labels, preprocess them and return in appropriate format.\n",
        "    \n",
        "    Parameters:\n",
        "    - data_dir: Directory where image files are stored\n",
        "    - label_file: JSON file containing labels\n",
        "    - img_size: Size to which images are to be resized\n",
        "    \n",
        "    Returns:\n",
        "    - images: List of preprocessed images\n",
        "    - targets: List of corresponding targets (labels)\n",
        "    \"\"\"\n",
        "    # Load labels\n",
        "    with open(label_file) as f:\n",
        "        labels = json.load(f)\n",
        "    \n",
        "    images = []\n",
        "    targets = []\n",
        "    \n",
        "    for filename, label in labels.items():\n",
        "        # Load image\n",
        "        img_path = os.path.join(data_dir, filename)\n",
        "        img = Image.open(img_path).convert(\"RGB\")  # Convert image to RGB\n",
        "\n",
        "        # Resize image and bounding boxes\n",
        "        old_width, old_height = img.size\n",
        "        img = img.resize(img_size)\n",
        "\n",
        "        # Scale bounding boxes\n",
        "        scale_x = img_size[0] / old_width\n",
        "        scale_y = img_size[1] / old_height\n",
        "        for box in label:\n",
        "            box['bbox'] = [box['bbox'][0] * scale_x,  # xmin\n",
        "                           box['bbox'][1] * scale_y,  # ymin\n",
        "                           box['bbox'][2] * scale_x,  # xmax\n",
        "                           box['bbox'][3] * scale_y]  # ymax\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_tensor = transforms.ToTensor()(img)\n",
        "        boxes_tensor = torch.tensor([box['bbox'] for box in label])\n",
        "        labels_tensor = torch.tensor([box['label'] for box in label])\n",
        "\n",
        "        # Prepare target\n",
        "        target = {}\n",
        "        target['boxes'] = boxes_tensor\n",
        "        target['labels'] = labels_tensor\n",
        "\n",
        "        images.append(img_tensor)\n",
        "        targets.append(target)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "# 2. Data Splitting\n",
        "\n",
        "def split_data(images, targets, train_ratio=0.7, val_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation, and testing sets.\n",
        "\n",
        "    Parameters:\n",
        "    - images: List of preprocessed images\n",
        "    - targets: List of corresponding targets (labels)\n",
        "    - train_ratio: Proportion of dataset to include in the train split (0.7 by default)\n",
        "    - val_ratio: Proportion of dataset to include in the validation split (0.15 by default)\n",
        "\n",
        "    Returns:\n",
        "    - train_images, train_targets: Training images and targets\n",
        "    - val_images, val_targets: Validation images and targets\n",
        "    - test_images, test_targets: Testing images and targets\n",
        "    \"\"\"\n",
        "    # Compute test ratio from train_ratio and val_ratio\n",
        "    test_ratio = 1.0 - train_ratio - val_ratio\n",
        "\n",
        "    # Split into train and temp\n",
        "    train_images, temp_images, train_targets, temp_targets = train_test_split(\n",
        "        images, targets, test_size=1-train_ratio, random_state=42, stratify=[t['labels'].tolist() for t in targets])\n",
        "\n",
        "    # Split temp into validation and test\n",
        "    val_images, test_images, val_targets, test_targets = train_test_split(\n",
        "        temp_images, temp_targets, test_size=test_ratio/(val_ratio+test_ratio), random_state=42, stratify=[t['labels'].tolist() for t in temp_targets])\n",
        "\n",
        "    return train_images, train_targets, val_images, val_targets, test_images, test_targets\n",
        "\n",
        "\n",
        "# 3. Model Configuration\n",
        "def configure_model(num_classes):\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# 4. Model Training\n",
        "def train_model(model, train_data, val_data, device, num_epochs=10):\n",
        "    # Move model to the right device\n",
        "    model.to(device)\n",
        "\n",
        "    # Define the optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    len_train = len(train_data)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for images, targets in train_data:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            total_train_loss += losses.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Training loss for this epoch\n",
        "        avg_train_loss = total_train_loss / len_train\n",
        "\n",
        "        # Evaluate on the validation data\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, targets in val_data:\n",
        "                images = list(image.to(device) for image in images)\n",
        "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                loss_dict = model(images, targets)\n",
        "\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                total_val_loss += losses.item()\n",
        "\n",
        "        # Validation loss for this epoch\n",
        "        avg_val_loss = total_val_loss / len(val_data)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{num_epochs}, Training loss: {avg_train_loss}, Validation loss: {avg_val_loss}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, data, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the given data.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The model to evaluate\n",
        "    - data: The data to evaluate the model on\n",
        "    - device: The device (cpu or gpu) to use for evaluation\n",
        "\n",
        "    Returns:\n",
        "    - avg_loss: The average loss of the model on the data\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for images, targets in data:\n",
        "            # Move images and targets to the right device\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Forward pass\n",
        "            loss_dict = model(images, targets)\n",
        "\n",
        "            # Compute total loss\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            total_loss += losses.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def test_model(model, test_data, device):\n",
        "    \"\"\"\n",
        "    Test the model on the given data.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The model to test\n",
        "    - test_data: The data to test the model on\n",
        "    - device: The device (cpu or gpu) to use for testing\n",
        "\n",
        "    Returns:\n",
        "    - predictions: The model's predictions on the test data\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for images, _ in test_data:  # We don't need targets here\n",
        "            # Move images to the right device\n",
        "            images = list(image.to(device) for image in images)\n",
        "\n",
        "            # Forward pass\n",
        "            pred = model(images)\n",
        "\n",
        "            # Move predictions back to cpu\n",
        "            pred = [{k: v.to('cpu') for k, v in p.items()} for p in pred]\n",
        "\n",
        "            predictions.extend(pred)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def predict(model, image_path, device, transform=None):\n",
        "    \"\"\"\n",
        "    Use the trained model to predict the objects in an image.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model\n",
        "    - image_path: Path to the image file\n",
        "    - device: The device (cpu or gpu) to use for inference\n",
        "    - transform (optional): Transformations to apply to the image before passing it to the model\n",
        "\n",
        "    Returns:\n",
        "    - prediction: The model's prediction on the image\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Apply transformations if specified\n",
        "    if transform is not None:\n",
        "        image = transform(image)\n",
        "\n",
        "    # Convert to PyTorch tensor and add an extra dimension\n",
        "    image = F.to_tensor(image).unsqueeze(0)\n",
        "\n",
        "    # Move image to the right device\n",
        "    image = image.to(device)\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        # Forward pass\n",
        "        prediction = model(image)\n",
        "\n",
        "    # Move prediction back to cpu and remove the extra dimension\n",
        "    prediction = [{k: v.to('cpu').squeeze(0) for k, v in prediction[0].items()}]\n",
        "\n",
        "    return prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main program ---\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "data_dir = 'path_to_your_data'\n",
        "label_file = 'full_path_to_json_file'\n",
        "images, labels = load_and_preprocess_data(data_dir, label_file)\n",
        "\n",
        "# 2. Data Splitting\n",
        "train_images, train_targets, val_images, val_targets, test_images, test_targets = split_data(images, labels)\n",
        "train_data = list(zip(train_images, train_targets))\n",
        "val_data = list(zip(val_images, val_targets))\n",
        "test_data = list(zip(test_images, test_targets))\n",
        "\n",
        "\n",
        "# 3. Model Configuration\n",
        "num_classes = 40  # 40 different types of objects\n",
        "model = configure_model(num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 4. Model Training\n",
        "num_epochs = 10\n",
        "train_model(model, train_data, val_data,  device, num_epochs)\n",
        "\n",
        "# 5. Model Evaluation\n",
        "evaluate_model(model, val_data)\n",
        "\n",
        "# 6. Model Testing\n",
        "test_model(model, test_data)\n",
        "\n",
        "# 7. Inference\n",
        "image_path = 'path_to_your_test_image'\n",
        "predict(model, image_path)\n"
      ],
      "metadata": {
        "id": "7wbqADQy4Ad1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}